{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python script with Weighted Hamming Kernel \n",
    "\n",
    "\n",
    "- A variation of the Hamming kernel where different features (members) have different importance.\n",
    "- **Kernel function:**\n",
    "\n",
    "$\n",
    "k(x, x') = \\exp \\left( - \\sum_i w_i \\mathbf{1} (x_i \\neq x'_i) \\right)\n",
    "$\n",
    "\n",
    "where $ w_i $ is a weight indicating the relative importance of design variable $ i $.\n",
    "\n",
    "### Example Use:\n",
    "Some truss members might be more critical than others. The weighted Hamming kernel allows prioritizing important members in the optimization process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Truss Design: [0 1 0 0 0]\n",
      "Best Score: 0.500660013179572\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "def weighted_hamming_kernel(X, Y=None, weights=None):\n",
    "    \"\"\"\n",
    "    Weighted Hamming Kernel for binary variables.\n",
    "    \n",
    "    Parameters:\n",
    "        X: ndarray (n_samples_X, n_features) - Binary input data.\n",
    "        Y: ndarray (n_samples_Y, n_features) - Binary input data (optional).\n",
    "        weights: ndarray (n_features,) - Feature weights (optional).\n",
    "    \n",
    "    Returns:\n",
    "        Kernel matrix K (n_samples_X, n_samples_Y)\n",
    "    \"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    Y = X if Y is None else np.atleast_2d(Y)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(X.shape[1])  # Default: equal weights\n",
    "\n",
    "    # Compute weighted Hamming distances\n",
    "    dists = np.sum(weights * (X[:, None, :] != Y[None, :, :]), axis=2)\n",
    "\n",
    "    # Apply exponential transformation to obtain kernel matrix\n",
    "    return np.exp(-dists)\n",
    "\n",
    "# Example: Binary truss topology optimization\n",
    "\n",
    "# Binary design space (each row represents a binary vector for truss topology)\n",
    "X_train = np.array([\n",
    "    [1, 0, 1, 1, 0], \n",
    "    [0, 1, 1, 0, 1], \n",
    "    [1, 1, 0, 1, 0],\n",
    "    [0, 0, 1, 1, 1]\n",
    "])\n",
    "\n",
    "# Simulated performance scores (e.g., compliance or weight minimization objective)\n",
    "y_train = np.array([0.8, 0.6, 0.9, 0.7])  # Lower is better\n",
    "\n",
    "# Define weights for the kernel (important members have higher weight)\n",
    "weights = np.array([1.5, 1.0, 0.5, 1.2, 0.8])\n",
    "\n",
    "# Create a Gaussian Process model\n",
    "gp = GaussianProcessRegressor(alpha=0.01, normalize_y=True)\n",
    "\n",
    "# Custom kernel function for GPR\n",
    "def custom_kernel(X, Y=None):\n",
    "    return weighted_hamming_kernel(X, Y, weights=weights)\n",
    "\n",
    "# Fit GP model using manually computed kernel matrix\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "# Define acquisition function (Expected Improvement)\n",
    "def acquisition(X_new, gp, X_train, y_train):\n",
    "    \"\"\"Expected Improvement Acquisition Function\"\"\"\n",
    "    mu, sigma = gp.predict(X_new, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-6)  # Numerical stability\n",
    "    best_y = np.min(y_train)\n",
    "    improvement = best_y - mu\n",
    "    return improvement * (improvement > 0)  # EI only for improving points\n",
    "\n",
    "# Bayesian Optimization loop: Find best topology\n",
    "def optimize_topology(X_train, y_train, gp, num_iters=1000):\n",
    "    best_topology = None\n",
    "    best_value = float('inf')\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        X_candidates = np.random.randint(0, 2, (10, 5))  # Generate random binary candidates\n",
    "        EI_values = acquisition(X_candidates, gp, X_train, y_train)\n",
    "        \n",
    "        best_idx = np.argmax(EI_values)\n",
    "        candidate = X_candidates[best_idx]\n",
    "\n",
    "        # Evaluate candidate (simulated performance score)\n",
    "        candidate_score = np.random.uniform(0.5, 1.0)\n",
    "\n",
    "        if candidate_score < best_value:\n",
    "            best_topology, best_value = candidate, candidate_score\n",
    "\n",
    "        # Update dataset\n",
    "        X_train = np.vstack([X_train, candidate])\n",
    "        y_train = np.append(y_train, candidate_score)\n",
    "\n",
    "        # Re-train GP\n",
    "        gp.fit(X_train, y_train)\n",
    "\n",
    "    return best_topology, best_value\n",
    "\n",
    "# Run optimization\n",
    "best_truss, best_score = optimize_topology(X_train, y_train, gp)\n",
    "print(\"Best Truss Design:\", best_truss)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Script with Tanimoto Kernel\n",
    "\n",
    "- Used for binary and discrete data.\n",
    "- Measures the similarity of two binary vectors using the **Tanimoto coefficient**:\n",
    "\n",
    "$\n",
    "k(x, x') = \\frac{x \\cdot x'}{||x||^2 + ||x'||^2 - x \\cdot x'}\n",
    "$\n",
    "\n",
    "This ensures that if two designs share more members, they are considered more similar.\n",
    "\n",
    "### Example Use:\n",
    "Comparing different truss topologies by the proportion of common structural members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Truss Design: [0 0 1 0 1]\n",
      "Best Score: 0.5000415384724269\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "def tanimoto_kernel(X, Y=None):\n",
    "    \"\"\"\n",
    "    Tanimoto Kernel for binary variables.\n",
    "    \n",
    "    Parameters:\n",
    "        X: ndarray (n_samples_X, n_features) - Binary input data.\n",
    "        Y: ndarray (n_samples_Y, n_features) - Binary input data (optional).\n",
    "    \n",
    "    Returns:\n",
    "        Kernel matrix K (n_samples_X, n_samples_Y)\n",
    "    \"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    Y = X if Y is None else np.atleast_2d(Y)\n",
    "\n",
    "    # Compute dot product (X · Y)\n",
    "    XY = np.dot(X, Y.T)\n",
    "\n",
    "    # Compute squared norms ||X||^2 and ||Y||^2\n",
    "    X_norm = np.sum(X**2, axis=1).reshape(-1, 1)\n",
    "    Y_norm = np.sum(Y**2, axis=1).reshape(1, -1)\n",
    "\n",
    "    # Compute Tanimoto Kernel\n",
    "    K = XY / (X_norm + Y_norm - XY + 1e-6)  # Small epsilon for numerical stability\n",
    "\n",
    "    return K\n",
    "\n",
    "# Example: Binary truss topology optimization\n",
    "\n",
    "# Binary design space (each row represents a binary vector for truss topology)\n",
    "X_train = np.array([\n",
    "    [1, 0, 1, 1, 0], \n",
    "    [0, 1, 1, 0, 1], \n",
    "    [1, 1, 0, 1, 0],\n",
    "    [0, 0, 1, 1, 1]\n",
    "])\n",
    "\n",
    "# Simulated performance scores (e.g., compliance or weight minimization objective)\n",
    "y_train = np.array([0.8, 0.6, 0.9, 0.7])  # Lower is better\n",
    "\n",
    "# Create a Gaussian Process model\n",
    "gp = GaussianProcessRegressor(alpha=0.01, normalize_y=True)\n",
    "\n",
    "# Custom kernel function for GPR\n",
    "def custom_kernel(X, Y=None):\n",
    "    return tanimoto_kernel(X, Y)\n",
    "\n",
    "# Fit GP model using manually computed kernel matrix\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "# Define acquisition function (Expected Improvement)\n",
    "def acquisition(X_new, gp, X_train, y_train):\n",
    "    \"\"\"Expected Improvement Acquisition Function\"\"\"\n",
    "    mu, sigma = gp.predict(X_new, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-6)  # Numerical stability\n",
    "    best_y = np.min(y_train)\n",
    "    improvement = best_y - mu\n",
    "    return improvement * (improvement > 0)  # EI only for improving points\n",
    "\n",
    "# Bayesian Optimization loop: Find best topology\n",
    "def optimize_topology(X_train, y_train, gp, num_iters=1000):\n",
    "    best_topology = None\n",
    "    best_value = float('inf')\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        X_candidates = np.random.randint(0, 2, (10, 5))  # Generate random binary candidates\n",
    "        EI_values = acquisition(X_candidates, gp, X_train, y_train)\n",
    "        \n",
    "        best_idx = np.argmax(EI_values)\n",
    "        candidate = X_candidates[best_idx]\n",
    "\n",
    "        # Evaluate candidate (simulated performance score)\n",
    "        candidate_score = np.random.uniform(0.5, 1.0)\n",
    "\n",
    "        if candidate_score < best_value:\n",
    "            best_topology, best_value = candidate, candidate_score\n",
    "\n",
    "        # Update dataset\n",
    "        X_train = np.vstack([X_train, candidate])\n",
    "        y_train = np.append(y_train, candidate_score)\n",
    "\n",
    "        # Re-train GP\n",
    "        gp.fit(X_train, y_train)\n",
    "\n",
    "    return best_topology, best_value\n",
    "\n",
    "# Run optimization\n",
    "best_truss, best_score = optimize_topology(X_train, y_train, gp)\n",
    "print(\"Best Truss Design:\", best_truss)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 105.50trial/s, best loss: 5.0] \n",
      "\n",
      "Best Topology (Binary Vector): [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n",
      "Total Weight (kg): 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "# Number of structural members\n",
    "NUM_MEMBERS = 10\n",
    "\n",
    "# Define the search space (binary variables for topology selection)\n",
    "search_space = [hp.choice(f'beam_{i}', [0, 1]) for i in range(NUM_MEMBERS)]\n",
    "\n",
    "# Simulated Structural Analysis Function (FEA proxy)\n",
    "def evaluate_topology(config):\n",
    "    \"\"\"\n",
    "    Evaluates the weight and structural efficiency of a gridshell topology.\n",
    "    The function returns an objective value where lower is better.\n",
    "    \"\"\"\n",
    "    weight_per_member = 10  # Assume each member has a weight of 10 kg\n",
    "    selected_members = np.array(config)  # Convert list to numpy array\n",
    "    \n",
    "    # Calculate total weight\n",
    "    total_weight = np.sum(selected_members) * weight_per_member\n",
    "\n",
    "    # Simulated \"stiffness penalty\" (more members = better stiffness)\n",
    "    stiffness_penalty = np.sum(selected_members)  # More members → better stability\n",
    "\n",
    "    # Objective: Minimize weight, but penalize for lack of stiffness\n",
    "    if stiffness_penalty == 0:\n",
    "        return 1000  # High penalty for empty structures\n",
    "    \n",
    "    performance_metric = total_weight - 5 * stiffness_penalty  # Balance weight & stiffness\n",
    "    return performance_metric  # Lower is better\n",
    "\n",
    "# Run Bayesian Optimization (TPE)\n",
    "trials = Trials()\n",
    "best_topology = fmin(\n",
    "    fn=evaluate_topology,  # Objective function\n",
    "    space=search_space,  # Search space\n",
    "    algo=tpe.suggest,  # Use TPE optimizer\n",
    "    max_evals=50,  # Number of iterations\n",
    "    trials=trials  # Store results\n",
    ")\n",
    "\n",
    "# Decode best topology (convert indices to binary)\n",
    "best_structure = [best_topology[f'beam_{i}'] for i in range(NUM_MEMBERS)]\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest Topology (Binary Vector):\", best_structure)\n",
    "print(\"Total Weight (kg):\", np.sum(best_structure) * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
